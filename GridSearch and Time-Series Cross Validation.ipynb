{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which lag is the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj = pd.read_excel('SanJuan_all.xlsx', index_col = 'Unnamed: 0')\n",
    "iq = pd.read_excel('Iquitos_all.xlsx', index_col = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Null with Month Mean\n",
    "def mean_replace(data):\n",
    "    monthly = dict()\n",
    "    for month in range(1,13):\n",
    "        monthly[month] = data[data.index.month == month]\n",
    "        for col in monthly[month]:\n",
    "            monthly[month][col] = monthly[month][col].fillna(np.mean(monthly[month][col]))\n",
    "    new = pd.DataFrame(columns=data.columns)\n",
    "    #for num in monthly.keys():\n",
    "    #    new = np.vstack([new, monthly[num]])\n",
    "    templist = list()\n",
    "    for a in monthly.keys():\n",
    "        templist.append(monthly[a])\n",
    "    result = pd.concat(templist).sort_index()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what I got from the Correlations notebook.\n",
    "- For San Juan, use the log-transformed data with top three correlated features and the lag of 26?\n",
    "- For Iquitos, use the ratio data by population with top three correlated features with the lag of 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch - San Juan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_x = sj.copy()\n",
    "sj_y = sj_x.pop('total_cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_x = sj_x.iloc[:-26]\n",
    "sj_y = sj_y.iloc[26:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_x['total_cases'] = sj_y\n",
    "sj_26corr = sj_x.corr()['total_cases'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_cases                              1.000000\n",
       "reanalysis_specific_humidity_g_per_kg    0.214854\n",
       "reanalysis_dew_point_temp_k              0.210690\n",
       "station_avg_temp_c                       0.204662\n",
       "station_max_temp_c                       0.200575\n",
       "reanalysis_max_air_temp_k                0.199302\n",
       "reanalysis_min_air_temp_k                0.192839\n",
       "reanalysis_air_temp_k                    0.185743\n",
       "station_min_temp_c                       0.181731\n",
       "reanalysis_avg_temp_k                    0.178910\n",
       "reanalysis_relative_humidity_percent     0.152666\n",
       "reanalysis_precip_amt_kg_per_m2          0.111116\n",
       "ndvi_nw                                  0.091284\n",
       "reanalysis_sat_precip_amt_mm             0.060250\n",
       "precipitation_amt_mm                     0.060250\n",
       "station_precip_mm                        0.050884\n",
       "ndvi_ne                                  0.046965\n",
       "station_diur_temp_rng_c                  0.039125\n",
       "ndvi_se                                  0.007234\n",
       "ndvi_sw                                  0.005894\n",
       "reanalysis_tdtr_k                       -0.073194\n",
       "Name: total_cases, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_26corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reanalysis_specific_humidity_g_per_kg', 'reanalysis_dew_point_temp_k',\n",
       "       'station_avg_temp_c', 'station_max_temp_c', 'reanalysis_max_air_temp_k',\n",
       "       'reanalysis_min_air_temp_k', 'reanalysis_air_temp_k',\n",
       "       'station_min_temp_c', 'reanalysis_avg_temp_k',\n",
       "       'reanalysis_relative_humidity_percent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_features = sj_26corr[1:11]\n",
    "sj_features.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pasin/opt/anaconda3/envs/env01/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "sj_used = sj_x[sj_features.index]\n",
    "sj_used = mean_replace(sj_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_pretrain = sj_used.iloc[:sj_used.shape[0] - sj_y.isnull().sum()]\n",
    "sj_try = sj_used.iloc[-sj_y.isnull().sum():]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_y = sj_y.dropna()\n",
    "sj_y.shape[0] == sj_pretrain.shape[0] # check if the numbers of rows are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * sj_y.shape[0])\n",
    "sj_x_train, sj_x_test = sj_pretrain.iloc[:train_size], sj_pretrain.iloc[train_size:]\n",
    "sj_y_train, sj_y_test = sj_y.iloc[:train_size], sj_y.iloc[train_size:]\n",
    "\n",
    "sj_y_train = np.log1p(sj_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm packages imported!\n",
      "Model selection packages imported!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Algorithms used for modeling\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC, RANSACRegressor, HuberRegressor, PassiveAggressiveRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import xgboost as xgb\n",
    "print('Algorithm packages imported!')\n",
    "\n",
    "# Model selection packages used for sampling dataset and optimising parameters\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "print('Model selection packages imported!')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_sj = SVR(kernel='linear')\n",
    "svr_sj_fit = svr_sj.fit(sj_x_train, sj_y_train)\n",
    "svr_sj_pred = svr_sj_fit.predict(sj_x_test)\n",
    "svr_sj_pred = [int(x) for x in np.expm1(svr_sj_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.747252747252746"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(svr_sj_pred, sj_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [SVR(), KernelRidge(), ElasticNet(), Lasso(), GradientBoostingRegressor(), BayesianRidge(), \n",
    "          LassoLarsIC(), RandomForestRegressor(), xgb.XGBRegressor(), RANSACRegressor(), HuberRegressor(),\n",
    "          PassiveAggressiveRegressor()]\n",
    "\n",
    "SVR_param_grid = {'kernel':['linear', 'rbf']}\n",
    "KR_param_grid = {'alpha': [0.1, 0.2, 0.3], 'coef0': [100], 'degree': [1, 2], 'gamma': [None], \n",
    "                 'kernel': ['linear']}\n",
    "EN_param_grid = {'alpha': [0.001, 0.005, 0.1], 'copy_X': [True], 'l1_ratio': [0.3, 0.6, 0.8], \n",
    "                 'fit_intercept': [True], 'normalize': [False], \n",
    "                 'precompute': [False], 'max_iter': [300, 900], \n",
    "                 'tol': [0.0005, 0.001, 0.002], 'selection': ['random'], \n",
    "                 'random_state': [None]}\n",
    "LASS_param_grid = {'alpha': [0.0005, 0.001, 0.005], 'copy_X': [True], \n",
    "                   'fit_intercept': [True], 'normalize': [False], 'precompute': [False], \n",
    "                   'max_iter': [300], 'tol': [0.01, 0.05, 0.1], \n",
    "                   'selection': ['random'], 'random_state': [None]}\n",
    "GB_param_grid = {'loss': ['huber'], 'learning_rate': [0.01, 0.1, 0.3], \n",
    "                 'n_estimators': [300, 1000], 'max_depth': [3, 5], \n",
    "                 'min_samples_split': [0.0025, 0.005], 'min_samples_leaf': [3, 5, 7]}\n",
    "BR_param_grid = {'n_iter': [200, 600], 'tol': [0.00001, 0.0001], \n",
    "                 'alpha_1': [0.00000001, 0.0000001, 0.000005], \n",
    "                 'alpha_2': [0.000005, 0.00001], 'lambda_1': [0.000005, 0.00001, 0.00005], \n",
    "                 'lambda_2': [0.00000001, 0.0000001], 'copy_X': [True]}\n",
    "LL_param_grid = {'criterion': ['aic'], 'normalize': [True], \n",
    "                 'max_iter': [100, 500], 'copy_X': [True], 'precompute': ['auto'], \n",
    "                 'eps': [0.000001, 0.00001]}\n",
    "RFR_param_grid = {'n_estimators': [50, 100, 200], 'max_features': ['auto'], \n",
    "                  'max_depth': [None, 2], 'min_samples_split': [5, 10], \n",
    "                  'min_samples_leaf': [2]}\n",
    "XGB_param_grid = {'max_depth': [3], 'learning_rate': [0.1], 'n_estimators': [300], \n",
    "                  'booster': ['gbtree'], 'gamma': [0], 'reg_alpha': [0.1],\n",
    "                  'reg_lambda': [0.7], 'max_delta_step': [0], 'min_child_weight': [1], \n",
    "                  'colsample_bytree': [0.5], 'colsample_bylevel': [0.2],\n",
    "                  'scale_pos_weight': [1]}\n",
    "RANSAC_param_grid = {'min_samples': [0.2, 0.5, 0.8], 'stop_probability': [0.1, 0.4, 0.8], 'max_skips': [10,30,50]}\n",
    "HB_param_grid = {'epsilon':[1.1, 1.35, 1.7, 2], 'max_iter':[100,300,500], 'alpha':[0.00001, 0.0001, 0.005, 0.01],\n",
    "                 'tol':[1e-5, 5e-5, 1e-4, 5e-4]}\n",
    "PAR_param_grid = {'C':[1.0, 1.5, 2], 'max_iter':[500,1000,5000], 'tol':[5e-4, 1e-3, 5e-3, 1e-2]}\n",
    "\n",
    "\n",
    "params_grid = [SVR_param_grid, KR_param_grid, EN_param_grid, LASS_param_grid, GB_param_grid, BR_param_grid, \n",
    "               LL_param_grid, RFR_param_grid, XGB_param_grid, RANSAC_param_grid, HB_param_grid, PAR_param_grid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
      "    gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "   Training Error = -0.8085489151930978\n",
      "   Testing Error = 13.747252747252746\n",
      "--------------\n",
      "\n",
      "Algorithm: KernelRidge(alpha=1, coef0=1, degree=3, gamma=None, kernel='linear',\n",
      "            kernel_params=None)\n",
      "   Training Error = -0.8229176693121404\n",
      "   Testing Error = 13.71062271062271\n",
      "--------------\n",
      "\n",
      "Algorithm: ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      "   Training Error = -0.8127106277951018\n",
      "   Testing Error = 13.454212454212454\n",
      "--------------\n",
      "\n",
      "Algorithm: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=None,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False)\n",
      "   Training Error = -0.8199259245201859\n",
      "   Testing Error = 13.373626373626374\n",
      "--------------\n",
      "\n",
      "Algorithm: GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "   Training Error = -0.8800141243237033\n",
      "   Testing Error = 13.765567765567766\n",
      "--------------\n",
      "\n",
      "Algorithm: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
      "              fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False)\n",
      "   Training Error = -0.8196927633953744\n",
      "   Testing Error = 13.413919413919414\n",
      "--------------\n",
      "\n",
      "Algorithm: LassoLarsIC(copy_X=True, criterion='aic', eps=2.220446049250313e-16,\n",
      "            fit_intercept=True, max_iter=500, normalize=True, positive=False,\n",
      "            precompute='auto', verbose=False)\n",
      "   Training Error = -0.8106936236700274\n",
      "   Testing Error = 13.505494505494505\n",
      "--------------\n",
      "\n",
      "Algorithm: RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
      "                      n_jobs=None, oob_score=False, random_state=None,\n",
      "                      verbose=0, warm_start=False)\n",
      "   Training Error = -0.8705116194004464\n",
      "   Testing Error = 14.703296703296703\n",
      "--------------\n",
      "\n",
      "[14:11:53] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:11:53] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:11:53] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:11:53] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Algorithm: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
      "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "             silent=None, subsample=1, verbosity=1)\n",
      "   Training Error = -0.9539523153215582\n",
      "   Testing Error = 14.315018315018316\n",
      "--------------\n",
      "\n",
      "Algorithm: RANSACRegressor(base_estimator=None, is_data_valid=None, is_model_valid=None,\n",
      "                loss='absolute_loss', max_skips=inf, max_trials=100,\n",
      "                min_samples=None, random_state=None, residual_threshold=None,\n",
      "                stop_n_inliers=inf, stop_probability=0.99, stop_score=inf)\n",
      "   Training Error = -0.775330781267477\n",
      "   Testing Error = 13.472527472527473\n",
      "--------------\n",
      "\n",
      "Algorithm: HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,\n",
      "               tol=1e-05, warm_start=False)\n",
      "   Training Error = -0.8140513219516746\n",
      "   Testing Error = 14.146520146520146\n",
      "--------------\n",
      "\n",
      "Algorithm: PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,\n",
      "                           epsilon=0.1, fit_intercept=True,\n",
      "                           loss='epsilon_insensitive', max_iter=1000,\n",
      "                           n_iter_no_change=5, random_state=None, shuffle=True,\n",
      "                           tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "   Training Error = -0.7851008039622104\n",
      "   Testing Error = 15.443223443223443\n",
      "--------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for algo in models:\n",
    "    gridsearch = GridSearchCV(algo, param_grid=params_grid[0], scoring='neg_mean_absolute_error')\n",
    "    params_grid.pop(0)\n",
    "    \n",
    "    gridsearch.fit(sj_x_train, sj_y_train)\n",
    "    grid_best = gridsearch.best_estimator_\n",
    "    algo_score = gridsearch.best_score_\n",
    "    prediction = [int(x) for x in np.expm1(gridsearch.predict(sj_x_test))]\n",
    "    test_score = mean_absolute_error(prediction, sj_y_test)\n",
    "    print('Algorithm:', algo)\n",
    "    print('   Training Error =', algo_score)\n",
    "    print('   Testing Error =', test_score)\n",
    "    print('--------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the best three features, RFR is the best model with testing error = 14.86\n",
    "- For the best eight features, RFR, 13.59\n",
    "- For the best ten features, Lasso, 13.40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_model = RANSACRegressor(base_estimator=None, is_data_valid=None, is_model_valid=None,\n",
    "                loss='absolute_loss', max_trials=100,\n",
    "                min_samples=None, random_state=None, residual_threshold=None,\n",
    "                stop_probability=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RANSACRegressor(base_estimator=None, is_data_valid=None, is_model_valid=None,\n",
       "                loss='absolute_loss', max_skips=inf, max_trials=100,\n",
       "                min_samples=None, random_state=None, residual_threshold=None,\n",
       "                stop_n_inliers=inf, stop_probability=0.99, stop_score=inf)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_model.fit(np.vstack((sj_x_train, sj_x_test)), np.hstack((np.expm1(sj_y_train), sj_y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_result = [int(x) for x in sj_model.predict(sj_try)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch - Iquitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reanalysis_specific_humidity_g_per_kg', 'reanalysis_dew_point_temp_k',\n",
       "       'reanalysis_min_air_temp_k', 'station_min_temp_c'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iq_corr = iq.corr()['total_cases'].sort_values(ascending = False)\n",
    "iq_features = iq_corr[1:5].index\n",
    "iq_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_cases                              1.000000\n",
       "reanalysis_specific_humidity_g_per_kg    0.236476\n",
       "reanalysis_dew_point_temp_k              0.230401\n",
       "reanalysis_min_air_temp_k                0.214514\n",
       "station_min_temp_c                       0.211702\n",
       "reanalysis_relative_humidity_percent     0.130083\n",
       "station_avg_temp_c                       0.113070\n",
       "reanalysis_precip_amt_kg_per_m2          0.101171\n",
       "reanalysis_air_temp_k                    0.097098\n",
       "reanalysis_sat_precip_amt_mm             0.090171\n",
       "precipitation_amt_mm                     0.090171\n",
       "reanalysis_avg_temp_k                    0.079872\n",
       "station_max_temp_c                       0.075279\n",
       "station_precip_mm                        0.042976\n",
       "ndvi_sw                                  0.032999\n",
       "ndvi_ne                                  0.020215\n",
       "ndvi_nw                                 -0.009586\n",
       "ndvi_se                                 -0.041067\n",
       "reanalysis_max_air_temp_k               -0.056474\n",
       "station_diur_temp_rng_c                 -0.058230\n",
       "reanalysis_tdtr_k                       -0.134425\n",
       "Name: total_cases, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iq_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_temp_used = iq[iq_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = iq_temp_used.shape[0] - iq.total_cases.isnull().sum()\n",
    "\n",
    "iq_pretrain, iq_try = iq.iloc[:train_size], iq.iloc[train_size:].drop('total_cases', axis = 1)\n",
    "iq_pretrain = mean_replace(iq_pretrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_pop = pd.read_csv('iq_pop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_number = int(0.7 * iq_pretrain.shape[0])\n",
    "iq_x_train, iq_x_test = iq_pretrain.iloc[:split_number], iq_pretrain.iloc[split_number:]\n",
    "iq_y_train = iq_x_train.pop('total_cases')\n",
    "iq_y_test = iq_x_test.pop('total_cases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(iq_y_train.shape[0]):\n",
    "    iq_y_train.iloc[i] = 100000 * iq_y_train.iloc[i] / iq_pop['Estimated_population'].iloc[np.argwhere(iq_pop['Year'] == iq_y_train.index[i].year)[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(iq_y_test.shape[0]):\n",
    "    iq_y_test.iloc[i] = 100000 * iq_y_test.iloc[i] / iq_pop['Estimated_population'].iloc[np.argwhere(iq_pop['Year'] == iq_y_test.index[i].year)[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [SVR(), KernelRidge(), ElasticNet(), Lasso(), GradientBoostingRegressor(), BayesianRidge(), \n",
    "          LassoLarsIC(), RandomForestRegressor(), xgb.XGBRegressor(), RANSACRegressor(), HuberRegressor(),\n",
    "          PassiveAggressiveRegressor()]\n",
    "\n",
    "SVR_param_grid = {'kernel':['linear', 'rbf']}\n",
    "KR_param_grid = {'alpha': [0.1, 0.2, 0.3], 'coef0': [100], 'degree': [1, 2], 'gamma': [None], \n",
    "                 'kernel': ['linear']}\n",
    "EN_param_grid = {'alpha': [0.001, 0.005, 0.1], 'copy_X': [True], 'l1_ratio': [0.3, 0.6, 0.8], \n",
    "                 'fit_intercept': [True], 'normalize': [False], \n",
    "                 'precompute': [False], 'max_iter': [300, 900], \n",
    "                 'tol': [0.0005, 0.001, 0.002], 'selection': ['random'], \n",
    "                 'random_state': [None]}\n",
    "LASS_param_grid = {'alpha': [0.0005, 0.001, 0.005], 'copy_X': [True], \n",
    "                   'fit_intercept': [True], 'normalize': [False], 'precompute': [False], \n",
    "                   'max_iter': [300], 'tol': [0.01, 0.05, 0.1], \n",
    "                   'selection': ['random'], 'random_state': [None]}\n",
    "GB_param_grid = {'loss': ['huber'], 'learning_rate': [0.01, 0.1, 0.3], \n",
    "                 'n_estimators': [300, 1000], 'max_depth': [3, 5], \n",
    "                 'min_samples_split': [0.0025, 0.005], 'min_samples_leaf': [3, 5, 7]}\n",
    "BR_param_grid = {'n_iter': [200, 600], 'tol': [0.00001, 0.0001], \n",
    "                 'alpha_1': [0.00000001, 0.0000001, 0.000005], \n",
    "                 'alpha_2': [0.000005, 0.00001], 'lambda_1': [0.000005, 0.00001, 0.00005], \n",
    "                 'lambda_2': [0.00000001, 0.0000001], 'copy_X': [True]}\n",
    "LL_param_grid = {'criterion': ['aic'], 'normalize': [True], \n",
    "                 'max_iter': [100, 500], 'copy_X': [True], 'precompute': ['auto'], \n",
    "                 'eps': [0.000001, 0.00001]}\n",
    "RFR_param_grid = {'n_estimators': [50, 100, 200], 'max_features': ['auto'], \n",
    "                  'max_depth': [None, 2], 'min_samples_split': [5, 10], \n",
    "                  'min_samples_leaf': [2]}\n",
    "XGB_param_grid = {'max_depth': [3], 'learning_rate': [0.1], 'n_estimators': [300], \n",
    "                  'booster': ['gbtree'], 'gamma': [0], 'reg_alpha': [0.1],\n",
    "                  'reg_lambda': [0.7], 'max_delta_step': [0], 'min_child_weight': [1], \n",
    "                  'colsample_bytree': [0.5], 'colsample_bylevel': [0.2],\n",
    "                  'scale_pos_weight': [1]}\n",
    "RANSAC_param_grid = {'min_samples': [0.2, 0.5, 0.8], 'stop_probability': [0.1, 0.4, 0.8], 'max_skips': [10,30,50]}\n",
    "HB_param_grid = {'epsilon':[1.1, 1.35, 1.7, 2], 'max_iter':[100,300,500], 'alpha':[0.00001, 0.0001, 0.005, 0.01],\n",
    "                 'tol':[1e-5, 5e-5, 1e-4, 5e-4]}\n",
    "PAR_param_grid = {'C':[1.0, 1.5, 2], 'max_iter':[500,1000,5000], 'tol':[5e-4, 1e-3, 5e-3, 1e-2]}\n",
    "\n",
    "\n",
    "params_grid = [SVR_param_grid, KR_param_grid, EN_param_grid, LASS_param_grid, GB_param_grid, BR_param_grid, \n",
    "               LL_param_grid, RFR_param_grid, XGB_param_grid, RANSAC_param_grid, HB_param_grid, PAR_param_grid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
      "    gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "   Training Error = -1.334788045361365\n",
      "   Testing Error = 1.907431380003696\n",
      "--------------\n",
      "\n",
      "Algorithm: KernelRidge(alpha=1, coef0=1, degree=3, gamma=None, kernel='linear',\n",
      "            kernel_params=None)\n",
      "   Training Error = -1.5230954554851093\n",
      "   Testing Error = 1.738513156920523\n",
      "--------------\n",
      "\n",
      "Algorithm: ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False)\n",
      "   Training Error = -1.4447027625361486\n",
      "   Testing Error = 1.7088325770928476\n",
      "--------------\n",
      "\n",
      "Algorithm: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=None,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False)\n",
      "   Training Error = -1.504332407753446\n",
      "   Testing Error = 1.7304185689738516\n",
      "--------------\n",
      "\n",
      "Algorithm: GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "   Training Error = -1.3454497288378635\n",
      "   Testing Error = 1.8231259085983642\n",
      "--------------\n",
      "\n",
      "Algorithm: BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
      "              fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
      "              normalize=False, tol=0.001, verbose=False)\n",
      "   Training Error = -1.4603240687132821\n",
      "   Testing Error = 1.7481168287243782\n",
      "--------------\n",
      "\n",
      "Algorithm: LassoLarsIC(copy_X=True, criterion='aic', eps=2.220446049250313e-16,\n",
      "            fit_intercept=True, max_iter=500, normalize=True, positive=False,\n",
      "            precompute='auto', verbose=False)\n",
      "   Training Error = -1.4370124166595477\n",
      "   Testing Error = 1.675812490147381\n",
      "--------------\n",
      "\n",
      "Algorithm: RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
      "                      n_jobs=None, oob_score=False, random_state=None,\n",
      "                      verbose=0, warm_start=False)\n",
      "   Training Error = -1.4184334135911232\n",
      "   Testing Error = 1.725441496498846\n",
      "--------------\n",
      "\n",
      "[14:19:10] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:19:10] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:19:10] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:19:10] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Algorithm: XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
      "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "             silent=None, subsample=1, verbosity=1)\n",
      "   Training Error = -1.7029287048024144\n",
      "   Testing Error = 1.9152596682150413\n",
      "--------------\n",
      "\n",
      "Algorithm: RANSACRegressor(base_estimator=None, is_data_valid=None, is_model_valid=None,\n",
      "                loss='absolute_loss', max_skips=inf, max_trials=100,\n",
      "                min_samples=None, random_state=None, residual_threshold=None,\n",
      "                stop_n_inliers=inf, stop_probability=0.99, stop_score=inf)\n",
      "   Training Error = -1.344103985578721\n",
      "   Testing Error = 1.7535294611650876\n",
      "--------------\n",
      "\n",
      "Algorithm: HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,\n",
      "               tol=1e-05, warm_start=False)\n",
      "   Training Error = -1.3124150408783186\n",
      "   Testing Error = 1.8965720099581473\n",
      "--------------\n",
      "\n",
      "Algorithm: PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,\n",
      "                           epsilon=0.1, fit_intercept=True,\n",
      "                           loss='epsilon_insensitive', max_iter=1000,\n",
      "                           n_iter_no_change=5, random_state=None, shuffle=True,\n",
      "                           tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "   Training Error = -1.3568034384869194\n",
      "   Testing Error = 2.2705086522809634\n",
      "--------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for algo in models:\n",
    "    gridsearch = GridSearchCV(algo, param_grid=params_grid[0], scoring='neg_mean_absolute_error')\n",
    "    params_grid.pop(0)\n",
    "    \n",
    "    gridsearch.fit(iq_x_train, iq_y_train)\n",
    "    grid_best = gridsearch.best_estimator_\n",
    "    algo_score = gridsearch.best_score_\n",
    "    prediction = [int(x) for x in gridsearch.predict(iq_x_test)]\n",
    "    test_score = mean_absolute_error(prediction, iq_y_test)\n",
    "    print('Algorithm:', algo)\n",
    "    print('   Training Error =', algo_score)\n",
    "    print('   Testing Error =', test_score)\n",
    "    print('--------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the best three features, LassoLarsIC is the best model with testing error = 1.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_model = LassoLarsIC(copy_X=True, criterion='aic', eps=2.220446049250313e-16,\n",
    "            fit_intercept=True, max_iter=500, normalize=True, positive=False,\n",
    "            precompute='auto', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoLarsIC(copy_X=True, criterion='aic', eps=2.220446049250313e-16,\n",
       "            fit_intercept=True, max_iter=500, normalize=True, positive=False,\n",
       "            precompute='auto', verbose=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iq_model.fit(np.vstack((iq_x_train, iq_x_test)), np.hstack((iq_y_train, iq_y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_result = iq_model.predict(iq_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(iq_result)):\n",
    "    iq_result[i] = iq_result[i] * iq_pop['Estimated_population'].iloc[np.argwhere(iq_pop['Year'] == iq_x_test.index[i].year)[0][0]] / 100000\n",
    "    iq_result[i] = int(iq_result[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4., 6., 5., 2., 2., 6., 6., 5., 7.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iq_result[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_result = [int(i) for i in np.hstack((sj_result, iq_result))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('submission_format.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.total_cases = all_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('Results/10log_0x10e5_ransac_llic.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
