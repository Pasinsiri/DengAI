{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm packages imported!\n",
      "Model selection packages imported!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Algorithms used for modeling\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC, RANSACRegressor, HuberRegressor, PassiveAggressiveRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import xgboost as xgb\n",
    "print('Algorithm packages imported!')\n",
    "\n",
    "# Model selection packages used for sampling dataset and optimising parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "print('Model selection packages imported!')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicing(predata, target, slicing_index):\n",
    "    data = predata.copy()\n",
    "    y_ = data.pop(target).iloc[slicing_index:]\n",
    "    new_ = data.iloc[:-slicing_index]\n",
    "    new_['total_cases'] = y_.values\n",
    "    return new_\n",
    "\n",
    "def splitting(data, target, train_ratio):\n",
    "    x_ = data.copy()\n",
    "    y_ = x_.pop(target)\n",
    "    if x_.shape[0] != y_.shape[0]:\n",
    "        raise Exception('Dimension not match!')\n",
    "        return\n",
    "    elif train_ratio >= 1:\n",
    "        raise Exception('Train Ratio > 1')\n",
    "        return\n",
    "    else:\n",
    "        num_train_ = int(train_ratio * x_.shape[0])\n",
    "        return x_.iloc[:num_train_], x_.iloc[num_train_:], y_.iloc[:num_train_], y_.iloc[num_train_:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_sj = pd.read_excel('Data/SJ_transformed2.xlsx', index_col = 'Unnamed: 0')\n",
    "pre_iq = pd.read_excel('Data/IQ_transformed2.xlsx', index_col = 'Unnamed: 0')\n",
    "iq_pop = pd.read_csv('Data/iq_pop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj = pre_sj[~pre_sj.total_cases.isnull()]\n",
    "sj_valid = pre_sj[pre_sj.total_cases.isnull()]\n",
    "iq = pre_iq[~pre_iq.total_cases.isnull()]\n",
    "iq_valid = pre_iq[pre_iq.total_cases.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For-Loop Average Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# San Juan\n",
    "sj_corr_dict = {}\n",
    "iq_corr_dict = {}\n",
    "for i in range(1, 50):\n",
    "    sj_corr_dict[i] = np.mean(slicing(sj, 'total_cases', i).corr()['total_cases'])\n",
    "    iq_corr_dict[i] = np.mean(slicing(iq, 'total_cases', i).corr()['total_cases'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection, select only features having correlation more than the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_var(city, lag, corr_dict):\n",
    "    avg_corr_ = corr_dict[lag]\n",
    "    sliced_data_ = slicing(city, 'total_cases', lag)\n",
    "    sliced_corr_ = sliced_data_.corr()['total_cases']\n",
    "    selected_corr_ = [col for col in sliced_corr_.index if sliced_corr_.loc[col] > avg_corr_]\n",
    "    return selected_corr_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_models = [SVR(), KernelRidge(), ElasticNet(), Lasso(), GradientBoostingRegressor(), BayesianRidge(), \n",
    "          LassoLarsIC(), RandomForestRegressor(), xgb.XGBRegressor(), RANSACRegressor(), HuberRegressor()]\n",
    "\n",
    "\n",
    "models = sj_models\n",
    "\n",
    "SVR_param_grid = {'kernel':['linear', 'rbf']}\n",
    "KR_param_grid = {'alpha': [0.1, 0.2, 0.3], 'coef0': [100], 'degree': [1, 2], 'gamma': [None], \n",
    "                 'kernel': ['linear']}\n",
    "EN_param_grid = {'alpha': [0.001, 0.005, 0.1], 'copy_X': [True], 'l1_ratio': [0.3, 0.6, 0.8], \n",
    "                 'fit_intercept': [True], 'normalize': [False], \n",
    "                 'precompute': [False], 'max_iter': [300, 900], \n",
    "                 'tol': [0.0005, 0.001, 0.002], 'selection': ['random'], \n",
    "                 'random_state': [None]}\n",
    "LASS_param_grid = {'alpha': [0.0005, 0.001, 0.005], 'copy_X': [True], \n",
    "                   'fit_intercept': [True], 'normalize': [False], 'precompute': [False], \n",
    "                   'max_iter': [300], 'tol': [0.01, 0.05, 0.1], \n",
    "                   'selection': ['random'], 'random_state': [None]}\n",
    "GB_param_grid = {'loss': ['huber'], 'learning_rate': [0.01, 0.1, 0.3], \n",
    "                 'n_estimators': [300, 1000], 'max_depth': [3, 5], \n",
    "                 'min_samples_split': [0.0025, 0.005], 'min_samples_leaf': [3, 5, 7]}\n",
    "BR_param_grid = {'n_iter': [200, 600], 'tol': [0.00001, 0.0001], \n",
    "                 'alpha_1': [0.00000001, 0.0000001, 0.000005], \n",
    "                 'alpha_2': [0.000005, 0.00001], 'lambda_1': [0.000005, 0.00001, 0.00005], \n",
    "                 'lambda_2': [0.00000001, 0.0000001], 'copy_X': [True]}\n",
    "LL_param_grid = {'criterion': ['aic'], 'normalize': [True], \n",
    "                 'max_iter': [100, 500], 'copy_X': [True], 'precompute': ['auto'], \n",
    "                 'eps': [0.000001, 0.00001]}\n",
    "RFR_param_grid = {'n_estimators': [50, 100, 200], 'max_features': ['auto'], \n",
    "                  'max_depth': [None, 2], 'min_samples_split': [5, 10], \n",
    "                  'min_samples_leaf': [2]}\n",
    "XGB_param_grid = {'max_depth': [3], 'learning_rate': [0.1], 'n_estimators': [300], \n",
    "                  'booster': ['gbtree'], 'gamma': [0], 'reg_alpha': [0.1],\n",
    "                  'reg_lambda': [0.7], 'max_delta_step': [0], 'min_child_weight': [1], \n",
    "                  'colsample_bytree': [0.5], 'colsample_bylevel': [0.2],\n",
    "                  'scale_pos_weight': [1]}\n",
    "RANSAC_param_grid = {'min_samples': [0.2, 0.5, 0.8], 'stop_probability': [0.1, 0.4, 0.8], 'max_skips': [10,30,50]}\n",
    "HB_param_grid = {'epsilon':[1.1, 1.35, 1.7, 2], 'max_iter':[100,300,500], 'alpha':[0.00001, 0.0001, 0.005, 0.01],\n",
    "                 'tol':[1e-5, 5e-5, 1e-4, 5e-4]}\n",
    "\n",
    "sj_params_grid = [SVR_param_grid, KR_param_grid, EN_param_grid, LASS_param_grid, GB_param_grid, BR_param_grid, \n",
    "               LL_param_grid, RFR_param_grid, XGB_param_grid, RANSAC_param_grid, HB_param_grid]\n",
    "\n",
    "params_grid = sj_params_grid\n",
    "\n",
    "params_dict = {}\n",
    "for i in range(len(models)):\n",
    "    params_dict[models[i]] = params_grid[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sj_error_cal(real, predict):\n",
    "    real_real = [int(x) for x in np.expm1(real)]\n",
    "    real_predict = [int(x) for x in np.expm1(predict)]\n",
    "    return mean_absolute_error(real_predict, real_real)\n",
    "\n",
    "def iq_error_cal(real, pre_predict, pop = iq_pop):\n",
    "    if real.shape[0] != pre_predict.shape[0]:\n",
    "        raise Exception(\"The shapes are not match with each other\")\n",
    "        return\n",
    "    else:\n",
    "        predict = pd.Series(pre_predict, index = real.index)\n",
    "        for i in range(real.shape[0]):\n",
    "            real.iloc[i] = real.iloc[i] * pop['Estimated_population'].iloc[np.argwhere(pop['Year'] == real.index.year[i])[0][0]] / 100000\n",
    "            predict.iloc[i] = predict.iloc[i] * pop['Estimated_population'].iloc[np.argwhere(pop['Year'] == predict.index.year[i])[0][0]] / 100000\n",
    "        return mean_absolute_error(real, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch_loop(city, models, params, x_train_, x_test_, y_train_, y_test_):\n",
    "    results = list()\n",
    "    if len(models) != len(params):\n",
    "        raise Exception('No. of models is not equal to no. of params')\n",
    "        return\n",
    "    for algo in models:\n",
    "        gridsearch = GridSearchCV(algo, param_grid = params[algo], scoring = 'neg_mean_absolute_error')\n",
    "        gridsearch.fit(x_train_, y_train_)\n",
    "        grid_best_ = gridsearch.best_estimator_\n",
    "        algo_score = gridsearch.best_score_\n",
    "        prediction_ = gridsearch.predict(x_test_)\n",
    "        if city == 'SJ':\n",
    "            test_score_ = sj_error_cal(y_test_, prediction_)\n",
    "        elif city == 'IQ':\n",
    "            test_score_ = iq_error_cal(y_test_, prediction_)\n",
    "        else:\n",
    "            raise Exception(\"Something is wrong!\")\n",
    "        results.append([grid_best_, -algo_score, test_score_])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP:\n",
    "1. For each lag, find the useful features using select_var.\n",
    "2. Split data to train and test using splitting(slicing(args.)).\n",
    "3. For each algorithm, use gridsearch to perform GridSearch algorithm, input city, models, params, and result table.\n",
    "4. Continuously iterate steps 1 and 2 with different lags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_result = pd.DataFrame(columns=['City', 'Lag', 'Training Size', 'No. of Features', 'Best Algorithm',\n",
    "#                                   'Training Score', 'Testing Score'])\n",
    "filename = 'Results/all_result_20200226_morning.csv'\n",
    "all_result = pd.read_csv(filename)\n",
    "all_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Lag</th>\n",
       "      <th>Training Size</th>\n",
       "      <th>No. of Features</th>\n",
       "      <th>Best Algorithm</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>IQ</td>\n",
       "      <td>16</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>LassoLarsIC(copy_X=True, criterion='aic', eps=...</td>\n",
       "      <td>1.643824</td>\n",
       "      <td>6.862141e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>IQ</td>\n",
       "      <td>16</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>RandomForestRegressor(bootstrap=True, ccp_alph...</td>\n",
       "      <td>1.598123</td>\n",
       "      <td>2.990783e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>IQ</td>\n",
       "      <td>16</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n",
       "      <td>1.801157</td>\n",
       "      <td>1.303585e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>IQ</td>\n",
       "      <td>16</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>RANSACRegressor(base_estimator=None, is_data_v...</td>\n",
       "      <td>1.499845</td>\n",
       "      <td>5.682507e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>IQ</td>\n",
       "      <td>16</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>HuberRegressor(alpha=0.005, epsilon=1.1, fit_i...</td>\n",
       "      <td>1.479605</td>\n",
       "      <td>2.477367e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    City  Lag  Training Size  No. of Features  \\\n",
       "347   IQ   16            0.7               20   \n",
       "348   IQ   16            0.7               20   \n",
       "349   IQ   16            0.7               20   \n",
       "350   IQ   16            0.7               20   \n",
       "351   IQ   16            0.7               20   \n",
       "\n",
       "                                        Best Algorithm  Training Score  \\\n",
       "347  LassoLarsIC(copy_X=True, criterion='aic', eps=...        1.643824   \n",
       "348  RandomForestRegressor(bootstrap=True, ccp_alph...        1.598123   \n",
       "349  XGBRegressor(base_score=0.5, booster='gbtree',...        1.801157   \n",
       "350  RANSACRegressor(base_estimator=None, is_data_v...        1.499845   \n",
       "351  HuberRegressor(alpha=0.005, epsilon=1.1, fit_i...        1.479605   \n",
       "\n",
       "     Testing Score  \n",
       "347   6.862141e+04  \n",
       "348   2.990783e+05  \n",
       "349   1.303585e+06  \n",
       "350   5.682507e+06  \n",
       "351   2.477367e+07  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_result.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## San Juan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start step 1 of lag 13\n",
      "Start step 2 of cv 0.7\n",
      "Start step 3\n",
      "[08:18:51] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[08:18:51] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[08:18:51] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[08:18:51] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[08:18:52] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[08:18:52] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Start cooling down\n",
      "Cooling down complete\n",
      "Start step 1 of lag 14\n",
      "Start step 2 of cv 0.7\n",
      "Start step 3\n",
      "[08:35:38] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[08:35:38] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[08:35:38] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[08:35:38] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[08:35:38] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[08:35:38] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Start cooling down\n",
      "Cooling down complete\n",
      "Start step 1 of lag 15\n",
      "Start step 2 of cv 0.7\n",
      "Start step 3\n",
      "[08:52:28] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[08:52:28] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[08:52:28] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[08:52:28] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[08:52:28] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[08:52:28] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Start cooling down\n",
      "Cooling down complete\n",
      "Start step 1 of lag 16\n",
      "Start step 2 of cv 0.7\n",
      "Start step 3\n",
      "[09:09:14] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[09:09:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[09:09:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[09:09:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[09:09:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[09:09:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "All iterations completed\n",
      "The latest file has been already saved!\n"
     ]
    }
   ],
   "source": [
    "city = 'SJ'\n",
    "laglist = range(13,17)\n",
    "cv_list = [0.7] #, 0.8]\n",
    "for lag in laglist:\n",
    "    print('Start step 1 of lag',lag)\n",
    "    # Step 1\n",
    "    #useful_features = select_var(sj, lag, sj_corr_dict)\n",
    "    #n_features = len(useful_features)\n",
    "    \n",
    "    # Step 2\n",
    "    for cv in cv_list:\n",
    "        print('Start step 2 of cv',cv)\n",
    "        x_train, x_test, y_train, y_test = splitting(slicing(sj, 'total_cases', lag), 'total_cases', cv)\n",
    "        \n",
    "        # Step 3\n",
    "        print('Start step 3')\n",
    "        #city, best_param, train_score, test_score = gridsearch_loop(city, models, params_dict, x_train, x_test, y_train, y_test)\n",
    "        #all_result = all_result.append({'City': city, 'Lag': lag, 'Training Size': cv,\n",
    "        #                                'No. of Features': n_features, 'Best Algorithm': best_param,\n",
    "        #                                'Training Score': train_score, 'Testing Score': test_score}, ignore_index=True)\n",
    "        results = gridsearch_loop(city, models, params_dict, x_train, x_test, y_train, y_test)\n",
    "        for result in results:\n",
    "            all_result = all_result.append({'City':city, 'Lag': lag, 'Training Size':cv, 'No. of Features': 20,\n",
    "                                            'Best Algorithm': result[0], 'Training Score': result[1],\n",
    "                                            'Testing Score': result[2]}, ignore_index=True)\n",
    "        if cv == cv_list[-1] and lag == laglist[-1]:\n",
    "            print('All iterations completed')\n",
    "        else:\n",
    "            print('Start cooling down')\n",
    "            time.sleep(180)\n",
    "            print('Cooling down complete') \n",
    "all_result.to_csv(filename, index = False)\n",
    "print('The latest file has been already saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Lag</th>\n",
       "      <th>Training Size</th>\n",
       "      <th>No. of Features</th>\n",
       "      <th>Best Algorithm</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>SJ</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>ElasticNet(alpha=0.1, copy_X=True, fit_interce...</td>\n",
       "      <td>0.816024</td>\n",
       "      <td>15.417857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>SJ</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>ElasticNet(alpha=0.1, copy_X=True, fit_interce...</td>\n",
       "      <td>0.804328</td>\n",
       "      <td>15.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>SJ</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>RandomForestRegressor(bootstrap=True, ccp_alph...</td>\n",
       "      <td>0.803831</td>\n",
       "      <td>15.612903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>SJ</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>RandomForestRegressor(bootstrap=True, ccp_alph...</td>\n",
       "      <td>0.841850</td>\n",
       "      <td>15.664286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>SJ</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>RandomForestRegressor(bootstrap=True, ccp_alph...</td>\n",
       "      <td>0.826544</td>\n",
       "      <td>15.673835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    City  Lag  Training Size  No. of Features  \\\n",
       "46    SJ    3            0.7               20   \n",
       "68    SJ    4            0.7               20   \n",
       "128   SJ    7            0.7               20   \n",
       "73    SJ    4            0.7               20   \n",
       "117   SJ    6            0.7               20   \n",
       "\n",
       "                                        Best Algorithm  Training Score  \\\n",
       "46   ElasticNet(alpha=0.1, copy_X=True, fit_interce...        0.816024   \n",
       "68   ElasticNet(alpha=0.1, copy_X=True, fit_interce...        0.804328   \n",
       "128  RandomForestRegressor(bootstrap=True, ccp_alph...        0.803831   \n",
       "73   RandomForestRegressor(bootstrap=True, ccp_alph...        0.841850   \n",
       "117  RandomForestRegressor(bootstrap=True, ccp_alph...        0.826544   \n",
       "\n",
       "     Testing Score  \n",
       "46       15.417857  \n",
       "68       15.450000  \n",
       "128      15.612903  \n",
       "73       15.664286  \n",
       "117      15.673835  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_result.to_csv('Results/all_result_20200225_morning.csv', index = False)\n",
    "all_result[all_result.City == 'SJ'].sort_values('Testing Score', ascending = True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"RANSACRegressor(base_estimator=None, is_data_valid=None, is_model_valid=None,\\n                loss='absolute_loss', max_skips=30, max_trials=100,\\n                min_samples=0.2, random_state=None, residual_threshold=None,\\n                stop_n_inliers=inf, stop_probability=0.8, stop_score=inf)\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_result.iloc[207]['Best Algorithm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_algo = all_result[all_result.City == 'SJ'].sort_values('Testing Score', ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE (2020-02-23): Remove XGBoost, RFR, and SVR from the model list, since they gave relatively higher criteria (error)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('Data/submission_format.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iquitos\n",
    "#iq_algo = all_result[all_result.City == 'IQ'].sort_values('Testing Score', ascending = True).iloc[0]['Best Algorithm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_algo = RANSACRegressor(base_estimator=None, is_data_valid=None, is_model_valid=None,loss='absolute_loss', max_skips=30, max_trials=100,min_samples=0.2, random_state=None, residual_threshold=None, stop_probability=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_selected_vars = select_var(iq, 2, iq_corr_dict)\n",
    "#iq_selected_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_lag = slicing(pre_iq[iq_selected_vars], 'total_cases', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_lag_train, iq_lag_test = iq_lag[~iq_lag.total_cases.isnull()], iq_lag[iq_lag.total_cases.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RANSACRegressor(base_estimator=None, is_data_valid=None, is_model_valid=None,\n",
       "                loss='absolute_loss', max_skips=30, max_trials=100,\n",
       "                min_samples=0.2, random_state=None, residual_threshold=None,\n",
       "                stop_n_inliers=inf, stop_probability=0.8, stop_score=inf)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iq_algo.fit(iq_lag_train.drop('total_cases', axis = 1), iq_lag_train.total_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_svr_result = iq_algo.predict(iq_lag_test.drop('total_cases', axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_result = pd.Series(iq_svr_result, index = iq_lag_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(iq_result.shape[0]):\n",
    "    #iq_result = real.iloc[i] * pop['Estimated_population'].iloc[np.argwhere(pop['Year'] == real.index.year[i])[0][0]] / 10e5\n",
    "    iq_result.iloc[i] = iq_result.iloc[i] * iq_pop['Estimated_population'].iloc[np.argwhere(iq_pop['Year'] == iq_result.index.year[i])[0][0]] / 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_result = [int(max(result, 0)) for result in iq_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.8,\\n           max_iter=300, normalize=False, positive=False, precompute=False,\\n           random_state=None, selection='random', tol=0.002, warm_start=False)\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# San Juan\n",
    "all_result[all_result.City == 'SJ'].sort_values('Testing Score', ascending = True).iloc[0]['Best Algorithm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_selected_vars = select_var(sj, 7, sj_corr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_algo = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',max_depth=2, max_features='auto', max_leaf_nodes=None,max_samples=None, min_impurity_decrease=0.0,min_impurity_split=None, min_samples_leaf=2,min_samples_split=5, min_weight_fraction_leaf=0.0,n_estimators=50, n_jobs=None, oob_score=False,random_state=None, verbose=0, warm_start=False)\n",
    "sj_lag = slicing(pre_sj[sj_selected_vars], 'total_cases', 7)\n",
    "sj_lag_train, sj_lag_test = sj_lag[~sj_lag.total_cases.isnull()], sj_lag[sj_lag.total_cases.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_algo.fit(sj_lag_train.drop('total_cases', axis = 1), sj_lag_train.total_cases)\n",
    "sj_preresult = sj_algo.predict(sj_lag_test.drop('total_cases', axis = 1))\n",
    "sj_result = pd.Series(sj_preresult, index = sj_lag_test.index)\n",
    "\n",
    "sj_result = [int(max(np.expm1(result), 0)) for result in sj_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.total_cases = np.hstack([sj_result, iq_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('Results/SJlag7_RF_IQlag2_HB.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Algorithm Name String Problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_debug(data, col = 'Best Algorithm', split_str = '\\n    '):\n",
    "    for i in range(data.shape[0]):\n",
    "        data[col][i] = ''.join(data[col][i].split(split_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Lag</th>\n",
       "      <th>Training Size</th>\n",
       "      <th>No. of Features</th>\n",
       "      <th>Best Algorithm</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Testing Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SJ</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>SVR(C=1.0, cache_size=200, coef0=0.0, degree=3...</td>\n",
       "      <td>0.840799</td>\n",
       "      <td>17.786477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SJ</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>KernelRidge(alpha=0.3, coef0=100, degree=1, ga...</td>\n",
       "      <td>0.861460</td>\n",
       "      <td>18.697509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SJ</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>ElasticNet(alpha=0.1, copy_X=True, fit_interce...</td>\n",
       "      <td>0.847556</td>\n",
       "      <td>15.989324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SJ</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>Lasso(alpha=0.005, copy_X=True, fit_intercept=...</td>\n",
       "      <td>0.852662</td>\n",
       "      <td>17.120996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SJ</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>GradientBoostingRegressor(alpha=0.9, ccp_alpha...</td>\n",
       "      <td>0.904697</td>\n",
       "      <td>18.818505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  City  Lag  Training Size  No. of Features  \\\n",
       "0   SJ    1            0.7               20   \n",
       "1   SJ    1            0.7               20   \n",
       "2   SJ    1            0.7               20   \n",
       "3   SJ    1            0.7               20   \n",
       "4   SJ    1            0.7               20   \n",
       "\n",
       "                                      Best Algorithm  Training Score  \\\n",
       "0  SVR(C=1.0, cache_size=200, coef0=0.0, degree=3...        0.840799   \n",
       "1  KernelRidge(alpha=0.3, coef0=100, degree=1, ga...        0.861460   \n",
       "2  ElasticNet(alpha=0.1, copy_X=True, fit_interce...        0.847556   \n",
       "3  Lasso(alpha=0.005, copy_X=True, fit_intercept=...        0.852662   \n",
       "4  GradientBoostingRegressor(alpha=0.9, ccp_alpha...        0.904697   \n",
       "\n",
       "   Testing Score  \n",
       "0      17.786477  \n",
       "1      18.697509  \n",
       "2      15.989324  \n",
       "3      17.120996  \n",
       "4      18.818505  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SVR' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-b6d0fb4726a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mname_debug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-85-821b4edb55ec>\u001b[0m in \u001b[0;36mname_debug\u001b[0;34m(data, col, split_str)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mname_debug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Best Algorithm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n    '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'SVR' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "name_debug(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx['Best Algorithm'][1] = ''.join(''.join(xx['Best Algorithm'][1].split('\\n    ')).split('        '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"KernelRidge(alpha=0.3, coef0=100, degree=1, gamma=None, kernel='linear',kernel_params=None)\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx['Best Algorithm'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx['Best Algorithm'][2] = ''.join(xx['Best Algorithm'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
